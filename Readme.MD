# üìû Projeto de Previs√£o de Churn - Telco Customer Churn

**Objetivo**: Prever a rotatividade de clientes (churn) em uma empresa de telecomunica√ß√µes usando XGBoost com dados processados no Databricks.

---

## üõ†Ô∏è Fluxo de Dados (Databricks)
| Camada       | Processamento                          |
|--------------|----------------------------------------|
| **Bronze**   | Dados brutos ingeridos da fonte        |
| **Silver**   | Tratamento de valores nulos/missing    |
| **Gold**     | Pr√©-processamento para ML:             |
|              | - Label Encoding & Binary Encoding     |
|              | - One-Hot Encoding                     |

![Data Pipeline](figs_/data_split.png)

---

## üîç An√°lise e Sele√ß√£o de Features
- **Correla√ß√£o com Target**: Identifica√ß√£o das vari√°veis num√©ricas mais relacionadas ao churn 

![Data Pipeline](figs_/corr_churn.png)

- **Teste Qui-Quadrado**: Filtragem estat√≠stica para selecionar apenas features com maior signific√¢ncia (p-valor > 20)
![Feature Selection](figs_/qui2.png)

---

## ‚öôÔ∏è Modelagem e  Pr√©-processamento
### Pr√©-processamento
  - Normaliza√ß√£o das vari√°veis num√©ricas (escala 0-1)
  - Balanceamento do dataset com SMOTE (aplicado apenas nos dados de treino)

### Busca de Hiperparametros
Para maximizar o desempenho do modelo XGBoost, foi realizada uma busca sistem√°tica de hiperpar√¢metros utilizando a biblioteca Optuna. O processo seguiu uma abordagem cient√≠fica, explorando combina√ß√µes inteligentes de par√¢metros para encontrar a configura√ß√£o ideal que minimiza o erro (RMSE) no conjunto de valida√ß√£o. O resultados foram:

| Hiperpar√¢metro       | Valor   |
|----------------------|---------|
| learning_rate        | 0.021   |
| max_depth           | 7       |
| subsample           | 0.812   |
| colsample_bytree    | 0.144   |
| min_child_weight    | 1       |


## üìà Resultados

## üìä Classification Report (XGBoost)

| Classe | Precision | Recall | F1-Score | Support |
|--------|-----------|--------|----------|---------|
| **N√£o Churn**  | 0.90      | 0.76   | 0.82     | 1033    |
| **Churn**  | 0.54      | 0.78   | 0.64     | 374     |

| M√©trica         | Precision | Recall | F1-Score | Support |
|-----------------|-----------|--------|----------|---------|
| **Accuracy**    | -         | -      | 0.76     | 1407    |
| **Macro Avg**   | 0.72      | 0.77   | 0.73     | 1407    |
| **Weighted Avg**| 0.81      | 0.76   | 0.77     | 1407    |

O modelo apresenta alta precis√£o (90%) para a classe majorit√°ria (N√£o-Churn), enquanto para a classe Churn priorizamos recall (78%) para capturar mais casos reais, ainda que com precision moderada (54%). A acur√°cia global de 76% reflete o desafio do desbalanceamento.


![roc](figs_/xgboost_roc.png)
![confusao](figs_/matriz_confusao.png)
A √°rea sob a curva ROC (AUC = 0.84) confirma uma boa capacidade discriminativa do modelo. No entanto, a an√°lise da curva Precision-Recall evidencia um dilema cr√≠tico:

  Para aumentar o recall (capturar mais churns reais), a precis√£o cai rapidamente, gerando mais falsos positivos.

  Se priorizarmos a precis√£o (reduzir falsos positivos), deixamos de identificar churns reais.



![importance](figs_/feature_importance_weight.png.png)


    M√©tricas de Otimiza√ß√£o: Foco em maximizar AUC-PR (Precision-Recall) devido 